{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "102c759c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jornv\\Programs\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing qhull: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7512/3810687578.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programs\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programs\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_output\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_SetOutputMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m from .utils._tags import (\n",
      "\u001b[1;32m~\\Programs\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdiscovery\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mall_estimators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreadpool_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m from .validation import (\n",
      "\u001b[1;32m~\\Programs\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mthreadpoolctl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programs\\lib\\site-packages\\scipy\\stats\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    439\u001b[0m \"\"\"\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmorestats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Programs\\lib\\site-packages\\scipy\\stats\\stats.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcdist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmeasurements\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m from scipy._lib._util import (check_random_state, MapWrapper,\n",
      "\u001b[1;32m~\\Programs\\lib\\site-packages\\scipy\\spatial\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mkdtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mckdtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mqhull\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_spherical_voronoi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSphericalVoronoi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_plotutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing qhull: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Read data\n",
    "dir = r\"C:\\Users\\jornv\\OneDrive\\Documenten\\Projects\\F1\\Data\\Formula1_ML.csv\"\n",
    "data = pd.read_csv(dir)\n",
    "\n",
    "# Convert variables to factors\n",
    "columns_to_factor = ['grid_t1', \n",
    "                     'grid', \n",
    "                     'position_driverstanding', \n",
    "                     'teammates_driverstanding',\n",
    "                     'wins_driverstanding', \n",
    "                     'wins_constructorstanding', \n",
    "                     'quarter',\n",
    "                     'grid_of_1_in_standings',\n",
    "                     'grid_of_2_in_standings',\n",
    "                     'grid_of_3_in_standings',\n",
    "                     'grid_of_4_in_standings',\n",
    "                     'grid_of_5_in_standings']\n",
    "\n",
    "data[columns_to_factor] = data[columns_to_factor].astype('category')\n",
    "\n",
    "# Split data into train and test sets\n",
    "def train_test_split_year(dataset, year):\n",
    "    train = dataset[(dataset['year'] < year) & (dataset['year'] > 1980) & (dataset['year'] != 2020) & (dataset['year'] != 2021)]\n",
    "    test = dataset[dataset['year'] == year]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c477161b",
   "metadata": {},
   "source": [
    "# Model trainer and tester SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2562e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010\n",
      "[[334  20]\n",
      " [ 20  31]]\n",
      "2011\n",
      "[[331  17]\n",
      " [ 18  34]]\n",
      "2012\n",
      "[[346  29]\n",
      " [ 29  25]]\n",
      "2013\n",
      "[[318  23]\n",
      " [ 23  31]]\n"
     ]
    }
   ],
   "source": [
    "for year in range(2010, 2023):\n",
    "    if year != 2020 and year != 2021:\n",
    "        # Split data into train and test sets\n",
    "        train, test = train_test_split_year(data, year)\n",
    "\n",
    "        # Select certain columns from test data\n",
    "        selected_columns = ['end_race_position_t1', \n",
    "                            'drivers_takeover_chance', \n",
    "                            'quarter', \n",
    "                            'grid_t1', \n",
    "                            'grid',\n",
    "                            'diff_grid_standing', \n",
    "                            'teammates_driverstanding', \n",
    "                            'overtakes_per_track_t1', \n",
    "                            'drivers_defense',\n",
    "                            'wins_driverstanding', \n",
    "                            'wins_constructorstanding', \n",
    "                            'position_driverstanding', \n",
    "                            'raceId', \n",
    "                            'teammates_defense', \n",
    "                            'teammates_takeover_chance']\n",
    "\n",
    "        test = test[selected_columns]\n",
    "        # Remove rows with missing values\n",
    "        test = test.dropna()\n",
    "\n",
    "        variables = ['drivers_takeover_chance', \n",
    "                      'quarter', \n",
    "                      'grid_t1', \n",
    "                      'grid', \n",
    "                      'diff_grid_standing', \n",
    "                      'teammates_driverstanding', \n",
    "                      'overtakes_per_track_t1', \n",
    "                      'drivers_defense', \n",
    "                      'wins_driverstanding', \n",
    "                      'wins_constructorstanding', \n",
    "                      'position_driverstanding',\n",
    "                      'end_race_position_t1',\n",
    "                      'teammates_defense',\n",
    "                      'teammates_takeover_chance'\n",
    "                    ]\n",
    "\n",
    "        train = train[variables].dropna()\n",
    "\n",
    "        # Split the data into features (X) and target variable (y)\n",
    "        X = train.drop('end_race_position_t1', axis=1)\n",
    "        y = train['end_race_position_t1']\n",
    "\n",
    "        # Oversample the minority class\n",
    "        ros = RandomOverSampler()\n",
    "        X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "        # Train the SVM model\n",
    "        svm_model = svm.SVC(kernel='rbf', gamma = 'scale', C = 30, probability=True)\n",
    "\n",
    "        svm_model.fit(X_resampled, y_resampled)\n",
    "        \n",
    "        # Predict on the test set\n",
    "        probabilities = svm_model.predict_proba(test.drop(['end_race_position_t1', 'raceId'], axis=1))[:, 1]\n",
    "\n",
    "        # Create a data frame with the predictions\n",
    "        values = test.copy()\n",
    "        values['predicted_probability'] = probabilities\n",
    "\n",
    "        # Group by 'raceId' and create 'top3' variable\n",
    "        values['top3'] = values.groupby('raceId')['predicted_probability'].rank(method='min', ascending=False) <= 3\n",
    "\n",
    "\n",
    "        # Create the confusion matrix\n",
    "        cm = confusion_matrix(values['top3'], values['end_race_position_t1'])\n",
    "        \n",
    "        print(year)\n",
    "        print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0ffead",
   "metadata": {},
   "source": [
    "# Model trainer and tester: Gradient boosting regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07cc58dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010\n",
      "[[336  18]\n",
      " [ 18  33]]\n",
      "2011\n",
      "[[330  18]\n",
      " [ 19  33]]\n",
      "2012\n",
      "[[350  25]\n",
      " [ 25  29]]\n",
      "2013\n",
      "[[319  22]\n",
      " [ 22  32]]\n",
      "2014\n",
      "[[292  19]\n",
      " [ 19  32]]\n",
      "2015\n",
      "[[286  16]\n",
      " [ 16  38]]\n",
      "2016\n",
      "[[339  20]\n",
      " [ 20  37]]\n",
      "2017\n",
      "[[300  18]\n",
      " [ 18  39]]\n",
      "2018\n",
      "[[320  20]\n",
      " [ 20  40]]\n",
      "2019\n",
      "[[324  16]\n",
      " [ 16  44]]\n",
      "2022\n",
      "[[312  26]\n",
      " [ 26  34]]\n",
      "2023\n",
      "[[252  17]\n",
      " [ 17  31]]\n"
     ]
    }
   ],
   "source": [
    "for year in range(2010, 2024):\n",
    "    if year != 2020 and year != 2021:\n",
    "        # Split data into train and test sets\n",
    "        train, test = train_test_split_year(data, year)\n",
    "\n",
    "        # Select certain columns from test data\n",
    "        selected_columns = ['end_race_position_t1', \n",
    "                            'drivers_takeover_chance', \n",
    "                            'quarter', \n",
    "                            'grid_t1', \n",
    "                            'diff_grid_standing', \n",
    "                            'teammates_driverstanding', \n",
    "                            'overtakes_per_track_t1', \n",
    "                            'drivers_defense',\n",
    "                            'wins_driverstanding', \n",
    "                            'wins_constructorstanding', \n",
    "                            'position_driverstanding', \n",
    "                            'raceId', \n",
    "                            'teammates_defense', \n",
    "                            'teammates_takeover_chance']\n",
    "\n",
    "        test = test[selected_columns]\n",
    "        # Remove rows with missing values\n",
    "        test = test.dropna()\n",
    "\n",
    "        variables = ['drivers_takeover_chance', \n",
    "                      'quarter', \n",
    "                      'grid_t1', \n",
    "                      'diff_grid_standing', \n",
    "                      'teammates_driverstanding', \n",
    "                      'overtakes_per_track_t1', \n",
    "                      'drivers_defense', \n",
    "                      'wins_driverstanding', \n",
    "                      'wins_constructorstanding', \n",
    "                      'position_driverstanding',\n",
    "                      'end_race_position_t1',\n",
    "                      'teammates_defense',\n",
    "                      'teammates_takeover_chance']\n",
    "\n",
    "        train = train[variables].dropna()\n",
    "\n",
    "        # Split the data into features (X) and target variable (y)\n",
    "        X = train.drop('end_race_position_t1', axis=1)\n",
    "        y = train['end_race_position_t1']\n",
    "\n",
    "        # Oversample the minority class\n",
    "        ros = RandomOverSampler()\n",
    "        X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "        \n",
    "        # Create the gradient boosting regressor\n",
    "        gbr = GradientBoostingRegressor(n_estimators=300, learning_rate=0.01, max_depth=8, random_state=42)\n",
    "\n",
    "        # Train the model\n",
    "        gbr.fit(X_resampled, y_resampled)\n",
    "        \n",
    "        # Predict on the test set\n",
    "        probabilities = gbr.predict(test.drop(['end_race_position_t1', 'raceId'], axis=1))\n",
    "\n",
    "        # Create a data frame with the predictions\n",
    "        values = test.copy()\n",
    "        values['predicted_probability'] = probabilities\n",
    "\n",
    "        # Group by 'raceId' and create 'top3' variable\n",
    "        values['top3'] = values.groupby('raceId')['predicted_probability'].rank(method='min', ascending=False) <= 3\n",
    "\n",
    "\n",
    "        # Create the confusion matrix\n",
    "        cm = confusion_matrix(values['top3'], values['end_race_position_t1'])\n",
    "        \n",
    "        print(year)\n",
    "        print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b436e846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[231  21]\n",
      " [  9  21]]\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split_year(data, 2023)\n",
    "\n",
    "# Select certain columns from test data\n",
    "selected_columns = ['end_race_position_t1', \n",
    "                    'drivers_takeover_chance', \n",
    "                    'quarter', \n",
    "                    'grid_t1', \n",
    "                    'diff_grid_standing', \n",
    "                    'teammates_driverstanding', \n",
    "                    'overtakes_per_track_t1', \n",
    "                    'drivers_defense',\n",
    "                    'wins_driverstanding', \n",
    "                    'wins_constructorstanding', \n",
    "                    'position_driverstanding', \n",
    "                    'raceId', \n",
    "                    'teammates_defense', \n",
    "                    'teammates_takeover_chance',\n",
    "                    'driverRef',\n",
    "                    'name_circuit']\n",
    "\n",
    "test = test[selected_columns]\n",
    "# Remove rows with missing values\n",
    "test = test.dropna()\n",
    "\n",
    "variables = ['drivers_takeover_chance', \n",
    "              'quarter', \n",
    "              'grid_t1', \n",
    "              'diff_grid_standing', \n",
    "              'teammates_driverstanding', \n",
    "              'overtakes_per_track_t1', \n",
    "              'drivers_defense', \n",
    "              'wins_driverstanding', \n",
    "              'wins_constructorstanding', \n",
    "              'position_driverstanding',\n",
    "              'end_race_position_t1',\n",
    "              'teammates_defense',\n",
    "              'teammates_takeover_chance']\n",
    "\n",
    "train = train[variables].dropna()\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = train.drop('end_race_position_t1', axis=1)\n",
    "y = train['end_race_position_t1']\n",
    "\n",
    "# Oversample the minority class\n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Create the gradient boosting regressor\n",
    "gbr = GradientBoostingRegressor(n_estimators=300, learning_rate=0.01, max_depth=8, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "gbr.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict on the test set\n",
    "probabilities = gbr.predict(test.drop(['end_race_position_t1', 'raceId', 'driverRef', 'name_circuit'], axis=1))\n",
    "\n",
    "# Create a data frame with the predictions\n",
    "values = test.copy()\n",
    "values['predicted_probability'] = probabilities\n",
    "\n",
    "# Group by 'raceId' and create 'top3' variable\n",
    "values['top3'] = values.groupby('raceId')['predicted_probability'].rank(method='min', ascending=False) <= 2\n",
    "\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(values['top3'], values['end_race_position_t1'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "925490b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "values.to_csv('C:\\\\Users\\\\jornv\\\\OneDrive\\\\Documenten\\\\Python data\\\\bets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f19de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
