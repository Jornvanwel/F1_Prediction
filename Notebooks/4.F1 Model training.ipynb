{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b9ee1352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "102c759c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target distribution before oversampling:\n",
      "results_position_t1\n",
      "0    10122\n",
      "1     1643\n",
      "Name: count, dtype: int64\n",
      "Training target distribution after oversampling:\n",
      "results_position_t1\n",
      "0    10122\n",
      "1    10122\n",
      "Name: count, dtype: int64\n",
      "Target variable distribution in the test set:\n",
      "results_position_t1\n",
      "0    381\n",
      "1     69\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jornv\\AppData\\Local\\Temp\\ipykernel_17764\\2877025831.py:4: DtypeWarning: Columns (19,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(os.path.join(prepared_path, 'F1_prepared.csv'))\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "current_dir = os.getcwd()\n",
    "prepared_path = os.path.normpath(os.path.join(current_dir, '..', '..', 'Data', 'Prepared'))\n",
    "data = pd.read_csv(os.path.join(prepared_path, 'F1_prepared.csv'))\n",
    "\n",
    "# Convert variables to categorical types\n",
    "columns_to_factor = [\n",
    "    'grid_t1', 'grid', 'driverstandings_position', 'teammates_driverstanding',\n",
    "    'driverstandings_wins', 'constructorstandings_wins', 'quarter'\n",
    "]\n",
    "data[columns_to_factor] = data[columns_to_factor].astype('category')\n",
    "\n",
    "# Select relevant columns\n",
    "selected_columns = [\n",
    "    'results_position_t1', 'drivers_takeover_chance', 'grid_t1', 'grid',\n",
    "    'diff_grid_standing', 'teammates_driverstanding', 'overtakes_per_track_t1', 'drivers_defense',\n",
    "    'driverstandings_wins', 'constructorstandings_wins', 'driverstandings_position', \n",
    "    'teammates_defense', 'teammates_takeover_chance', 'date_diff', 'is_round_1', 'year', 'date', 'raceId', 'driverId', 'round'\n",
    "]\n",
    "\n",
    "data = data[selected_columns].dropna()\n",
    "\n",
    "# Label encode categorical columns\n",
    "label_encoders = {}\n",
    "for col in data.select_dtypes(['category']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Sort data by date and raceId\n",
    "data = data.sort_values(by=['date'])\n",
    "\n",
    "# Split data into train and test sets based on year\n",
    "train_data = data[(data['year'] > 1990) & (data['year'] < 2023)]\n",
    "test_data = data[data['year'] >= 2023]\n",
    "\n",
    "X_train = train_data.drop(['results_position_t1', 'year', 'raceId', 'date'], axis=1)\n",
    "y_train = train_data['results_position_t1']\n",
    "\n",
    "X_test = test_data.drop(['results_position_t1', 'year', 'raceId', 'date'], axis=1)\n",
    "y_test = test_data['results_position_t1']\n",
    "\n",
    "# Check the distribution of the target variable\n",
    "print(\"Training target distribution before oversampling:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Oversample the minority class\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the distribution of the target variable after oversampling\n",
    "print(\"Training target distribution after oversampling:\")\n",
    "print(pd.Series(y_resampled).value_counts())\n",
    "\n",
    "# Scale the features\n",
    "scaler = MinMaxScaler()\n",
    "X_resampled = scaler.fit_transform(X_resampled)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Reshape for LSTM\n",
    "# The reshaping should consider the sequences based on the 'date_diff'\n",
    "def reshape_for_lstm(X, sequence_length=20):\n",
    "    X_lstm = []\n",
    "    for i in range(0, len(X) - sequence_length + 1):\n",
    "        X_lstm.append(X[i:i + sequence_length])\n",
    "    return np.array(X_lstm)\n",
    "\n",
    "X_train_reshaped = reshape_for_lstm(X_resampled)\n",
    "X_test_reshaped = reshape_for_lstm(X_test)\n",
    "\n",
    "# Adjust y_resampled and y_test for LSTM input\n",
    "def reshape_target(y, sequence_length=20):\n",
    "    y_lstm = []\n",
    "    for i in range(sequence_length - 1, len(y)):\n",
    "        y_lstm.append(y[i])\n",
    "    return np.array(y_lstm)\n",
    "\n",
    "y_train_reshaped = reshape_target(y_resampled)\n",
    "y_test_reshaped = reshape_target(y_test.values)\n",
    "\n",
    "# Verify target variable distribution in the test set\n",
    "print(\"Target variable distribution in the test set:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c477161b",
   "metadata": {},
   "source": [
    "# Model trainer and tester LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b2562e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jornv\\AppData\\Local\\Temp\\ipykernel_17764\\2589050984.py:13: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1686/1686 [==============================] - 19s 10ms/step - loss: 0.1684 - accuracy: 0.9405\n",
      "Epoch 2/5\n",
      "1686/1686 [==============================] - 16s 9ms/step - loss: 0.1193 - accuracy: 0.9491\n",
      "Epoch 3/5\n",
      "1686/1686 [==============================] - 16s 9ms/step - loss: 0.1060 - accuracy: 0.9544\n",
      "Epoch 4/5\n",
      "1686/1686 [==============================] - 16s 9ms/step - loss: 0.1025 - accuracy: 0.9537\n",
      "Epoch 5/5\n",
      "1686/1686 [==============================] - 17s 10ms/step - loss: 0.1003 - accuracy: 0.9548\n",
      "211/211 [==============================] - 1s 3ms/step\n",
      "Epoch 1/5\n",
      "1686/1686 [==============================] - 19s 10ms/step - loss: 0.2222 - accuracy: 0.9229\n",
      "Epoch 2/5\n",
      "1686/1686 [==============================] - 16s 10ms/step - loss: 0.1647 - accuracy: 0.9320\n",
      "Epoch 3/5\n",
      "1686/1686 [==============================] - 16s 10ms/step - loss: 0.1363 - accuracy: 0.9396\n",
      "Epoch 4/5\n",
      "1686/1686 [==============================] - 16s 9ms/step - loss: 0.1331 - accuracy: 0.9424\n",
      "Epoch 5/5\n",
      "1686/1686 [==============================] - 16s 10ms/step - loss: 0.1282 - accuracy: 0.9430\n",
      "211/211 [==============================] - 1s 3ms/step\n",
      "Epoch 1/5\n",
      "1686/1686 [==============================] - 18s 10ms/step - loss: 0.3621 - accuracy: 0.8704\n",
      "Epoch 2/5\n",
      "1686/1686 [==============================] - 15s 9ms/step - loss: 0.2488 - accuracy: 0.8903\n",
      "Epoch 3/5\n",
      "1686/1686 [==============================] - 16s 9ms/step - loss: 0.2336 - accuracy: 0.8976\n",
      "Epoch 4/5\n",
      "1686/1686 [==============================] - 15s 9ms/step - loss: 0.2294 - accuracy: 0.8978\n",
      "Epoch 5/5\n",
      "1686/1686 [==============================] - 17s 10ms/step - loss: 0.2274 - accuracy: 0.9000\n",
      "211/211 [==============================] - 1s 3ms/step\n",
      "Epoch 1/5\n",
      "2529/2529 [==============================] - 28s 10ms/step - loss: 0.2260 - accuracy: 0.9155\n",
      "Epoch 2/5\n",
      "2529/2529 [==============================] - 25s 10ms/step - loss: 0.1601 - accuracy: 0.9304\n",
      "Epoch 3/5\n",
      "2529/2529 [==============================] - 24s 10ms/step - loss: 0.1537 - accuracy: 0.9315\n",
      "Epoch 4/5\n",
      "2529/2529 [==============================] - 27s 11ms/step - loss: 0.1506 - accuracy: 0.9333\n",
      "Epoch 5/5\n",
      "2529/2529 [==============================] - 25s 10ms/step - loss: 0.1493 - accuracy: 0.9336\n",
      "Best parameters: {'batch_size': 8, 'dropout_rate': 0.3, 'epochs': 5, 'neurons': 20, 'optimizer': 'rmsprop'}\n",
      "Best precision score: 0.8486522217910005\n",
      "14/14 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Function to create LSTM model with hyperparameters\n",
    "def create_model(neurons, dropout_rate, optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(neurons))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap Keras model for use in scikit-learn\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "# Define hyperparameters grid\n",
    "param_grid = {\n",
    "    'neurons': [20],\n",
    "    'dropout_rate': [0.3],\n",
    "    'optimizer': ['rmsprop'],\n",
    "    'batch_size': [8],\n",
    "    'epochs': [5]\n",
    "}\n",
    "\n",
    "# Implement grid search with cross-validation\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='precision')\n",
    "grid_result = grid.fit(X_train_reshaped, y_train_reshaped, callbacks=[EarlyStopping(monitor='loss', patience=3)])\n",
    "\n",
    "# Output best parameters and best score\n",
    "print(f\"Best parameters: {grid_result.best_params_}\")\n",
    "print(f\"Best precision score: {grid_result.best_score_}\")\n",
    "\n",
    "# Predict on the test set with the best model\n",
    "best_model = grid_result.best_estimator_\n",
    "simple_probabilities = best_model.predict_proba(X_test_reshaped)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3d09a878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix with Best Model:\n",
      "[[343  22]\n",
      " [ 21  45]]\n",
      "Precision: 0.6716417910447762\n",
      "Predicted probabilities: [0.0400831  0.00360181 0.00239264 0.00624136 0.0528387  0.08432904\n",
      " 0.04975397 0.28000182 0.00140125 0.08636601]\n",
      "Actual test labels: [0 0 0 0 0 1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Ensure that y_test_reshaped matches the length of X_test_reshaped\n",
    "y_test_reshaped = y_test_reshaped[:len(X_test_reshaped)]\n",
    "\n",
    "# Create a data frame with the predictions and X_test values\n",
    "simple_values = pd.DataFrame(X_test[:len(simple_probabilities)])\n",
    "simple_values['predicted_probability'] = simple_probabilities\n",
    "simple_values['results_position_t1'] = y_test_reshaped\n",
    "\n",
    "# Group by 'raceId' and create 'top3' variable\n",
    "simple_values['raceId'] = test_data.reset_index().loc[simple_values.index, 'raceId']\n",
    "simple_values['top3'] = simple_values.groupby('raceId')['predicted_probability'].rank(method='min', ascending=False) <= 3\n",
    "\n",
    "# Create the confusion matrix\n",
    "simple_cm = confusion_matrix(simple_values['results_position_t1'], simple_values['top3'])\n",
    "\n",
    "print(\"Confusion Matrix with Best Model:\")\n",
    "print(simple_cm)\n",
    "\n",
    "# Calculate and print precision\n",
    "precision = precision_score(simple_values['results_position_t1'], simple_values['top3'])\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "# Check some of the predictions\n",
    "print(\"Predicted probabilities:\", simple_probabilities[:10])\n",
    "print(\"Actual test labels:\", y_test_reshaped[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243536c2",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936a5ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
