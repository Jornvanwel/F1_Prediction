{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce51d745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jornv\\Programs\\lib\\site-packages\\fastf1\\plotting.py:37: UserWarning: Failed to import optional dependency 'matplotlib'!Plotting functionality will be unavailable!\n",
      "  warnings.warn(\"Failed to import optional dependency 'matplotlib'!\"\n",
      "C:\\Users\\jornv\\Programs\\lib\\site-packages\\fastf1\\plotting.py:42: UserWarning: Failed to import optional dependency 'timple'!Plotting of timedelta values will be restricted!\n",
      "  warnings.warn(\"Failed to import optional dependency 'timple'!\"\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "import fastf1 as ff1\n",
    "from fastf1.core import Laps\n",
    "from fastf1 import utils\n",
    "from fastf1 import plotting\n",
    "import csv\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70e47c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff1.Cache.enable_cache(r'C:\\Users\\jornv\\OneDrive\\Documenten\\Fast f1 Cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee95190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "races = pd.read_csv(r\"C:\\Users\\jornv\\OneDrive\\Documenten\\Projects\\F1\\Data\\Fact\\races.csv\", on_bad_lines='skip', header= 0, delimiter= ',')\n",
    "drivers = pd.read_csv(r\"C:\\Users\\jornv\\OneDrive\\Documenten\\Projects\\F1\\Data\\Fact\\drivers.csv\", on_bad_lines='skip', header= 0, delimiter= ',')\n",
    "constructors = pd.read_csv(r\"C:\\Users\\jornv\\OneDrive\\Documenten\\Projects\\F1\\Data\\Fact\\constructors.csv\", on_bad_lines='skip', header= 0, delimiter= ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c31dfad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff1_retriever(races_df, racetype):\n",
    "    laps_total = pd.DataFrame()\n",
    "    messages_total = pd.DataFrame()\n",
    "    results_total = pd.DataFrame()\n",
    "    weather_total = pd.DataFrame()\n",
    "    races_df.replace(r'\\N', np.NaN, inplace=True)\n",
    "    races_df = races_df.astype({\"date\": \"datetime64\", \"quali_date\": \"datetime64\"})\n",
    "    \n",
    "    races_miss = []  # Initialize races_miss list\n",
    "    \n",
    "    if racetype == 'Q':\n",
    "        qualifying = pd.read_csv(r\"C:\\Users\\jornv\\OneDrive\\Documenten\\Projects\\F1\\Data\\Fact\\qualifying.csv\", on_bad_lines='skip', header=0, delimiter=',')\n",
    "        races_miss = qualifying[\"raceId\"].unique().tolist()  # Update races_miss list with qualifying raceIds\n",
    "    \n",
    "    if racetype == 'R':\n",
    "        results = pd.read_csv(r\"C:\\Users\\jornv\\OneDrive\\Documenten\\Projects\\F1\\Data\\Fact\\results.csv\", on_bad_lines='skip', header=0, delimiter=',')\n",
    "        races_miss = results[\"raceId\"].unique().tolist()  # Update races_miss list with results raceIds\n",
    "    \n",
    "    races_df = races_df[~races_df['raceId'].isin(races_miss)]\n",
    "    races_df['name_short'] = races_df['name'].str.replace(' Grand Prix', '')\n",
    "\n",
    "    for index, row in races_df.iterrows():\n",
    "        race = row['name_short']\n",
    "        year = row['year']\n",
    "        raceId = row['raceId']\n",
    "        date = row['quali_date']\n",
    "        \n",
    "        if date <= pd.to_datetime('today'):\n",
    "            print(f\"Retrieving data for year {year} and race {race}\")\n",
    "            try:\n",
    "                qualification = ff1.get_session(year, f'{race}', racetype)\n",
    "                qualification.load()\n",
    "\n",
    "                Q_laps = qualification.laps\n",
    "                Q_messages = qualification.race_control_messages\n",
    "                Q_results = qualification.results\n",
    "                Q_weather = qualification.weather_data\n",
    "\n",
    "                Q_messages['Year'] = year\n",
    "                Q_laps[\"Year\"] = year\n",
    "                Q_results[\"Year\"] = year\n",
    "                Q_weather[\"Year\"] = year\n",
    "                \n",
    "                Q_messages['raceId'] = raceId\n",
    "                Q_laps['raceId'] = raceId\n",
    "                Q_results['raceId'] = raceId\n",
    "                Q_weather['raceId'] = raceId\n",
    "\n",
    "                laps_total = laps_total.append(Q_laps)\n",
    "                messages_total = messages_total.append(Q_messages)\n",
    "                results_total = results_total.append(Q_results)\n",
    "                weather_total = weather_total.append(Q_weather)\n",
    "                print(\"Succeeded in retrieving data\")\n",
    "            except:\n",
    "                print(\"Failed to retrieve data\")\n",
    "                pass\n",
    "            \n",
    "    return laps_total, messages_total, results_total, weather_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "791bf932-f01e-4a07-834b-4a1bb7cf0120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove accents and convert to lowercase\n",
    "def normalize_text(text):\n",
    "    # Normalize text to NFD form (Decomposes characters into base characters and combining marks)\n",
    "    normalized = unicodedata.normalize('NFD', text)\n",
    "    # Filter out the combining marks (accents)\n",
    "    no_accents = ''.join([c for c in normalized if unicodedata.category(c) != 'Mn'])\n",
    "    # Convert to lowercase\n",
    "    lower_case = no_accents.lower()\n",
    "    return lower_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7c2b251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving data for year 2024 and race Saudi Arabian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Saudi Arabian Grand Prix - Qualifying [v2.2.7]\n",
      "api            INFO \tNo cached data found for driver_info. Loading data...\n",
      "api            INFO \tFetching driver list...\n",
      "api            INFO \tData has been written to cache!\n",
      "api            INFO \tNo cached data found for timing_data. Loading data...\n",
      "api            INFO \tFetching timing data...\n",
      "api            INFO \tParsing timing data...\n",
      "api            INFO \tData has been written to cache!\n",
      "api            INFO \tNo cached data found for timing_app_data. Loading data...\n",
      "api            INFO \tFetching timing app data...\n",
      "api            INFO \tData has been written to cache!\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tNo cached data found for session_status_data. Loading data...\n",
      "api            INFO \tFetching session status data...\n",
      "api            INFO \tData has been written to cache!\n",
      "api            INFO \tNo cached data found for track_status_data. Loading data...\n",
      "api            INFO \tFetching track status data...\n",
      "api            INFO \tData has been written to cache!\n",
      "api            INFO \tNo cached data found for car_data. Loading data...\n",
      "api            INFO \tFetching car data...\n",
      "api            INFO \tParsing car data...\n",
      "api            INFO \tData has been written to cache!\n",
      "api            INFO \tNo cached data found for position_data. Loading data...\n",
      "api            INFO \tFetching position data...\n",
      "api            INFO \tParsing position data...\n",
      "api            INFO \tData has been written to cache!\n",
      "api            INFO \tNo cached data found for weather_data. Loading data...\n",
      "api            INFO \tFetching weather data...\n",
      "api            INFO \tData has been written to cache!\n",
      "api            INFO \tNo cached data found for race_control_messages. Loading data...\n",
      "api            INFO \tFetching race control messages...\n",
      "api            INFO \tData has been written to cache!\n",
      "core           INFO \tFinished loading data for 20 drivers: ['1', '16', '11', '14', '81', '4', '63', '44', '22', '18', '38', '23', '20', '3', '27', '77', '31', '10', '2', '24']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded in retrieving data\n"
     ]
    }
   ],
   "source": [
    "Q_laps, Q_messages, Q_results, Q_weather = ff1_retriever(races, 'Q')\n",
    "R_laps, R_messages, R_results, R_weather = ff1_retriever(races, 'R')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e661f3a0",
   "metadata": {},
   "source": [
    "## Adding new qualifying data to qualifying.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "401a9947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drivers: Empty SessionResults\n",
      "Columns: [FirstName, LastName]\n",
      "Index: [] are missing\n"
     ]
    }
   ],
   "source": [
    "drivers['forename_corrected'] = drivers['forename'].apply(normalize_text)\n",
    "drivers['surname_corrected'] = drivers['surname'].apply(normalize_text)\n",
    "\n",
    "Q_results['FirstName_corrected'] = Q_results['FirstName'].apply(normalize_text)\n",
    "Q_results['LastName_corrected'] = Q_results['LastName'].apply(normalize_text)\n",
    "\n",
    "qualifying_df = Q_results.merge(drivers, left_on = ['FirstName_corrected', 'LastName_corrected'], right_on = ['forename_corrected', 'surname_corrected'], how = 'left')\n",
    "\n",
    "print(f\"Drivers: {qualifying_df[qualifying_df['forename'].isna()][['FirstName', 'LastName']].drop_duplicates().to_string(index=False, header=False)} are missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32670ae8-55e2-4bd6-988c-a40a2a53ad24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructors: Empty SessionResults\n",
      "Columns: [TeamName_corrected]\n",
      "Index: [] are missing\n"
     ]
    }
   ],
   "source": [
    "constructors['name_corrected'] = constructors['name'].apply(normalize_text)\n",
    "\n",
    "qualifying_df['TeamName_corrected'] = qualifying_df['TeamName'].apply(normalize_text)\n",
    "\n",
    "qualifying_df = qualifying_df.merge(constructors, left_on = ['TeamName_corrected'], right_on = ['name_corrected'], how = 'left')\n",
    "\n",
    "print(f\"Constructors: {qualifying_df[qualifying_df['name_corrected'].isna()][['TeamName_corrected']].drop_duplicates().to_string(index=False, header=False)} are missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42655a19-b465-4769-800f-bab8e3f6cdd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "162960c6-7ec4-484d-9368-5c5718474853",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualifying_df = qualifying_df[['raceId', 'driverId', 'constructorId', 'DriverNumber', 'Position', 'Q1', 'Q2', 'Q3']]\n",
    "qualifying_df.columns = ['raceId', 'driverId', 'constructorId', 'number', 'position', 'q1', 'q2', 'q3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89ec851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_df = pd.read_csv(r\"C:\\Users\\jornv\\OneDrive\\Documenten\\Projects\\F1\\Data\\Fact\\qualifying.csv\", on_bad_lines='skip', header=0, delimiter=',')\n",
    "next_id = Q_df['qualifyId'].max() + 1\n",
    "qualifying_df.insert(0, 'qualifyId', range(next_id, next_id + len(qualifying_df)))\n",
    "Q_df = Q_df.append(qualifying_df)\n",
    "Q_df.to_csv(r\"C:\\Users\\jornv\\OneDrive\\Documenten\\Projects\\F1\\Data\\Fact\\qualifying.csv\", mode='w', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8925523e",
   "metadata": {},
   "source": [
    "## Adding new result data to result.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a1fa5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = R_results.merge(drivers, left_on = ['FirstName', 'Abbreviation'], right_on = ['forename', 'code'], how = 'left')\n",
    "results_df = results_df.merge(constructors, left_on = 'TeamName', right_on = 'name', how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f066796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_laps['fastest_time'] = R_laps.groupby(['DriverNumber', 'raceId'])['LapTime'].transform('min')\n",
    "quickest_lap = R_laps[R_laps['fastest_time'] == R_laps['LapTime']]\n",
    "results_df = results_df.merge(quickest_lap, on = ['DriverNumber', 'raceId'], how = 'left')\n",
    "results_df = results_df[['raceId', 'driverId', 'constructorId', 'DriverNumber', 'GridPosition', 'Position', 'Points', 'LapNumber', 'LapTime', 'SpeedFL']]\n",
    "results_df.columns = ['raceId', 'driverId', 'constructorId', 'number', 'grid', 'positionOrder', 'points', 'fastestLap', 'fastestLapTime', 'fastestLapSpeed']\n",
    "results_df['position'] = results_df['positionOrder']\n",
    "results_df['positionText'] = results_df['positionOrder']\n",
    "results_df = results_df.sort_values(by=['raceId', 'positionOrder'], ascending=[True, True])\n",
    "results_df['rank'] = results_df.groupby('raceId')['fastestLapTime'].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b77a5431",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_df = pd.read_csv(r\"C:\\Users\\jornv\\OneDrive\\Documenten\\Python data\\Formula 1 from kaggle\\results.csv\", on_bad_lines='skip', header= 0, delimiter= ',')\n",
    "next_id = R_df['resultId'].max() + 1\n",
    "results_df.insert(0, 'resultId', range(next_id, next_id + len(results_df)))\n",
    "R_df = R_df.append(results_df)\n",
    "R_df.to_csv(r\"C:\\Users\\jornv\\OneDrive\\Documenten\\Python data\\Fact\\results.csv\", mode='w', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7bc388",
   "metadata": {},
   "source": [
    "## Adding new driverstanding data to driverstanding.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75734ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df.merge(races, on = 'raceId', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04c11dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['win'] = results_df['positionOrder'].apply(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d08e7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "driverpoint = []\n",
    "driver_standings_df = pd.read_csv(r\"C:\\Users\\jornv\\OneDrive\\Documenten\\Python data\\Formula 1 from kaggle\\driver_standings.csv\", on_bad_lines='skip', header= 0, delimiter= ',')\n",
    "driver_standings = driver_standings_df[\"raceId\"].unique()\n",
    "for index, row in results_df.iterrows():\n",
    "    driverId = row['driverId']\n",
    "    raceId = row['raceId']\n",
    "    year = row['year']\n",
    "    roundId = row[\"round\"]\n",
    "    if raceId not in driver_standings:\n",
    "        driver_results = results_df[(results_df['driverId'] == driverId) & (results_df['year'] == year) & (results_df['round'] <= roundId)]['points'].sum()\n",
    "        win = results_df[(results_df['driverId'] == driverId) & (results_df['year'] == year) & (results_df['raceId'] <= raceId)]['win'].sum()\n",
    "        driverpoint.append((raceId, driverId, driver_results, win))\n",
    "        \n",
    "driverpoint_df = pd.DataFrame(driverpoint, columns =['raceId', 'driverId',  \"points\", \"wins\"])\n",
    "driverpoint_df['position'] = driverpoint_df.groupby('raceId')['points'].rank(ascending=False)\n",
    "driverpoint_df['positionText'] = driverpoint_df['position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fb54fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "next_id = driver_standings_df['driverStandingsId'].max() + 1\n",
    "\n",
    "driverpoint_df.insert(0, 'driverStandingsId', range(next_id, next_id + len(driverpoint_df)))\n",
    "\n",
    "driver_standings_df = driver_standings_df.append(driverpoint_df)\n",
    "\n",
    "driver_standings_df.to_csv(r\"C:\\Users\\jornv\\OneDrive\\Documenten\\Python data\\Fact\\driver_standings.csv\", mode='w', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d45f34e",
   "metadata": {},
   "source": [
    "## Adding new constructorstanding data to constructorstanding.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c88ad485",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df.merge(driverpoint_df, on = ['raceId', 'driverId'], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e35f14b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructors_standings = results_df.groupby(['raceId', 'constructorId'], as_index = False)[['points_y', 'wins']].sum()\n",
    "constructors_standings = constructors_standings.apply(lambda x: x.reset_index(drop=True))\n",
    "constructors_standings['position'] = constructors_standings.groupby('raceId')['points_y'].rank(ascending=False)\n",
    "constructors_standings['positionText'] = constructors_standings['position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6c524cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructors_standings = constructors_standings[['raceId', 'constructorId', 'points_y', 'position', 'positionText', 'wins']]\n",
    "constructors_standings.columns = ['raceId', 'constructorId', 'points', 'position', 'positionText', 'wins']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1876dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructor_standings_df = pd.read_csv(r\"C:\\Users\\jornv\\OneDrive\\Documenten\\Python data\\Formula 1 from kaggle\\constructor_standings.csv\", on_bad_lines='skip', header= 0, delimiter= ',')\n",
    "\n",
    "next_id = constructor_standings_df['constructorStandingsId'].max() + 1\n",
    "\n",
    "constructors_standings.insert(0, 'constructorStandingsId', range(next_id, next_id + len(constructors_standings)))\n",
    "\n",
    "constructor_standings_df = constructor_standings_df.append(constructors_standings)\n",
    "\n",
    "constructor_standings_df.to_csv(r\"C:\\Users\\jornv\\OneDrive\\Documenten\\Python data\\Fact\\constructor_standings.csv\", mode='w', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f60768",
   "metadata": {},
   "source": [
    "## Adding new laps data to lap_times.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a79d836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df = results_df.merge(drivers, on = 'driverId', how = 'left')\n",
    "laps_df = R_laps.merge(results_df[['driverId', 'number']].drop_duplicates(), left_on = ['DriverNumber'], right_on = ['number'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f1b3298",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_df = laps_df[['raceId', 'driverId', 'LapNumber', 'LapTime']]\n",
    "laps_df = laps_df.sort_values(by=['raceId', 'driverId', 'LapNumber'], ascending=[True, True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b5ac919",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_df['milliseconds'] = laps_df['LapTime'].dt.total_seconds() * 1000\n",
    "laps_df['CumulativeSum'] = laps_df.groupby(['driverId', 'raceId'])['milliseconds'].cumsum()\n",
    "# Convert 'milliseconds' column to seconds\n",
    "laps_df['seconds'] = laps_df['milliseconds'] / 1000\n",
    "laps_df['seconds'] = laps_df['seconds'].fillna(0)\n",
    "# Get minutes, seconds and milliseconds\n",
    "laps_df['time'] = laps_df['seconds'].apply(lambda x: f\"{int(x // 60):02d}:{int(x % 60):02d}.{int((x % 1)*1000):06d}\")\n",
    "\n",
    "# If you don't need the temporary 'seconds' column anymore, you can drop it\n",
    "laps_df = laps_df.drop(['seconds'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43406f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_df['position'] = laps_df.groupby(['raceId', 'LapNumber'])['CumulativeSum'].rank(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8706fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_times_df = pd.read_csv(r\"C:\\Users\\jornv\\OneDrive\\Documenten\\Python data\\Formula 1 from kaggle\\lap_times.csv\", on_bad_lines='skip', header= 0, delimiter= ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53b5e05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_df = laps_df[['raceId', 'driverId', 'LapNumber', 'position', 'time', 'milliseconds']]\n",
    "laps_df.columns = ['raceId', 'driverId', 'lap', 'position', 'time', 'milliseconds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "874a0065",
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_times_df = lap_times_df.append(laps_df)\n",
    "lap_times_df.to_csv(r\"C:\\Users\\jornv\\OneDrive\\Documenten\\Python data\\Fact\\lap_times.csv\", mode='w', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7afa678c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'fastf1.core.Laps'>\n",
      "Int64Index: 4257 entries, 0 to 879\n",
      "Data columns (total 30 columns):\n",
      " #   Column              Non-Null Count  Dtype          \n",
      "---  ------              --------------  -----          \n",
      " 0   Time                4257 non-null   timedelta64[ns]\n",
      " 1   DriverNumber        4257 non-null   object         \n",
      " 2   LapTime             4059 non-null   timedelta64[ns]\n",
      " 3   LapNumber           4257 non-null   float64        \n",
      " 4   Stint               4257 non-null   float64        \n",
      " 5   PitOutTime          271 non-null    timedelta64[ns]\n",
      " 6   PitInTime           201 non-null    timedelta64[ns]\n",
      " 7   Sector1Time         4149 non-null   timedelta64[ns]\n",
      " 8   Sector2Time         4253 non-null   timedelta64[ns]\n",
      " 9   Sector3Time         4253 non-null   timedelta64[ns]\n",
      " 10  Sector1SessionTime  4149 non-null   timedelta64[ns]\n",
      " 11  Sector2SessionTime  4253 non-null   timedelta64[ns]\n",
      " 12  Sector3SessionTime  4253 non-null   timedelta64[ns]\n",
      " 13  SpeedI1             3534 non-null   float64        \n",
      " 14  SpeedI2             4253 non-null   float64        \n",
      " 15  SpeedFL             4049 non-null   float64        \n",
      " 16  SpeedST             3654 non-null   float64        \n",
      " 17  IsPersonalBest      4255 non-null   object         \n",
      " 18  Compound            4257 non-null   object         \n",
      " 19  TyreLife            3908 non-null   float64        \n",
      " 20  FreshTyre           4120 non-null   object         \n",
      " 21  LapStartTime        4257 non-null   timedelta64[ns]\n",
      " 22  Team                4257 non-null   object         \n",
      " 23  Driver              4257 non-null   object         \n",
      " 24  TrackStatus         4257 non-null   object         \n",
      " 25  IsAccurate          4257 non-null   object         \n",
      " 26  LapStartDate        4257 non-null   datetime64[ns] \n",
      " 27  Year                4257 non-null   int64          \n",
      " 28  raceId              4257 non-null   int64          \n",
      " 29  fastest_time        4255 non-null   timedelta64[ns]\n",
      "dtypes: datetime64[ns](1), float64(7), int64(2), object(8), timedelta64[ns](12)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "R_laps.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d82c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb19c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
